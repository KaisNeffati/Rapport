%
% File: chap01.tex
% Author: Victor F. Brena-Medina
% Description: Introduction chapter where the biology goes.
%
\let\textcircled=\pgftextcircled
\chapter{Implementation}
\label{chap:intro}

\initial{I}n this chapter we will talk abour the steps that
%=======
\section{Work environnement}
\label{sec:sec01}
This part presents the Hardware and Software environment available for this project.
\subsection{Hardware environnement}
\label{sec:sec01}
In our project we developed our application using a computer with the following characteristics : 
\begin{itemize}
  \item Process Intel Core i5 4310M .
  \item Memory RAM: 16 GB .
  \item Space Discs: 500 GB.
\end{itemize}

\section{Software environnement}
\label{sec:sec01}
We've used for our project the following Software :
\begin{itemize}
  \item VMware Workstation : Our application is deployed under VMware Workstation virtualization
   platform as a set of decoupled service. Each service per container.
  \item Centos 7 : Our application operating system is Centos 7 carring Docker as demon. 
  \item Docker : is our main virtualization tool and our containers manager.
  \item Intellij idea : is our application Back End IDE , we used it for Scala and java (spring) developement.
  \item Visual Studio Code : is our application Front End IDE , we used it for angular 2 and webpack (TypeScript developement).
\end{itemize}
\section{Realized work}
\label{sec:sec01}
\subsection{Environnement preparation}
\label{sec:sec01}
Our application require some containers preparation. The following list contain all needed containers.
\begin{itemize}
  \item Kafka container : used for collecting data and stream them through a message queue. This container does not existe in dockerhub repository so we should Dockerize it(Dockerize
   kafka means create a container that contain kafka)
  \item Zookeeper container : used to save brokers address and messages offsets . this container exists in docker hub.
  \item Scala container : used to build the Hadoop container.This container does not existe in dockerhub repository so we should Dockerize it
  \item Hadoop container : used to build the spark container and provide HDFS persistance and YARN (ressource manager) for the spark jobs. This container does not existe with
   the Hadoop 2.7 and centos 7 version, so we should Dockerize it
  \item Spark container : used to to consume the data from kafka , process it then feed it to the serving layer (persisting results in cassandra).
  \item Cassandra container : used as a serving layer . this container exists in docker hub , we will be using the 2.2 cassandra version.
  \item Zeppelin container : used as a notebook to interpret Cassandra and spark then display the results in a dashboard.
  \item Spring boot containers : we need some containers that carry each one a microservice. This containers just need to have a JVM.
  \item Mongodb containers : each service is linked to a mongodb container. this containers exists in dockerhub.
  \item FrontEnd container : container for the angular dashboard.
\end{itemize}
\subsubsection{Dockernize Tools}
\label{sec:sec01}
In this section we present the process of dockernizing our containers .All installation setps are written 
in Dockerfiles and each container has an OS kernel. We will be using alpine and centos 7.
\paragraph{Dockernize Kafka}
\label{sec:sec01}
To dockernize this container, we will start by putting a base OS version wich is alpine linux . The next step is the Jdk installation. After fixing all paths we move to install
kafka.
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.2\textheight]{fig01/KafkaContainer}
	\mycaption[filiales et clients de Sofrecom.]{Kafka container}
	\label{fig:FilialesEtClients}
\end{figure}
\paragraph{Dockernize Scala}
\label{sec:sec01}
To dockernize this container, we will start by putting a base OS version wich is centos 7 . 
The next step is the Jdk installation. After fixing all paths we move to install Scala.
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.2\textheight]{fig01/ScalaContainer}
	\mycaption[filiales et clients de Sofrecom.]{Scala container}
	\label{fig:FilialesEtClients}
\end{figure}
\paragraph{Dockernize Hadoop}
\label{sec:sec01}
To dockernize this container, we will start from the previous Scala container. 
The next step is the Hadoop installation which takes too much time due to the big configuration amount.
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.2\textheight]{fig01/HadoopContainer}
	\mycaption[filiales et clients de Sofrecom.]{Hadoop Container}
	\label{fig:FilialesEtClients}
\end{figure}
\newpage
After dockernizing Hadoop 2.7 we are able now to see some Doshboard.
Hadoop YARN ResourceManager HTTP UI :
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.5	\textheight]{fig01/HadoopYarnDashboard}
	\mycaption[filiales et clients de Sofrecom.]{Hadoop YARN ResourceManager HTTP UI }
	\label{fig:FilialesEtClients}
\end{figure}
\newpage
Hadoop HDFS NameNode HTTP UI :\\
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.3\textheight]{fig01/HDFSNameNode}
	\mycaption[filiales et clients de Sofrecom.]{Hadoop HDFS NameNode HTTP UI}
	\label{fig:FilialesEtClients}
\end{figure}
\newline
We can Check Files existance through the HDFS NameNode UI :\\
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.3\textheight]{fig01/BrowserFilesHDFS}
	\mycaption[filiales et clients de Sofrecom.]{Browser files HDFS}
	\label{fig:FilialesEtClients}
\end{figure}
\paragraph{Dockernize Spark}
\label{sec:sec01}
This container is the main container. We built the last two ones for this step. This container is based on the haddop one . Spark uses HDFS to persist data
and uses YARN as a ResourceManager.This container require much more then the last one in terms of configuration. We chose to built spark on yarn to benefit the real sparks power. \\
So spark present in totaly 3 deployment mode :\\
Standalone deployment: With the standalone deployment one we can statically
allocate resources on all or a subset of machines in a Hadoop cluster and run
Spark side by side with Hadoop MR. The user can then run arbitrary Spark jobs
on his HDFS data. Its simplicity makes this the deployment of choice for many
Hadoop 1.x users.\\
Hadoop Yarn deployment: Hadoop users who have already deployed or are
planning to deploy Hadoop Yarn can simply run Spark on YARN without any pre-
installation or administrative access required. This allows users to easily
integrate Spark in their Hadoop stack and take advantage of the full power of
Spark, as well as of other components running on top of Spark.\\
Spark In MapReduce (SIMR): For the Hadoop users that are not running YARN
yet, another option, in addition to the standalone deployment, is to use SIMR to
launch Spark jobs inside MapReduce. With SIMR, users can start experimenting
with Spark and use its shell within a couple of minutes after downloading it! This
tremendously lowers the barrier of deployment, and lets virtually everyone play
with Spark.\\
\textit{
Notice:
 Spark is an in-Memory data processing framwork so when trying to configure it make sure you put the right RM consumption.
}
In our case we ve used 1 core o
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.2\textheight]{fig01/SparkContainer}
	\mycaption[filiales et clients de Sofrecom.]{Spark container}
	\label{fig:FilialesEtClients}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[height=0.2\textheight]{fig01/SparkFinalContainer}
	\mycaption[filiales et clients de Sofrecom.]{Spark deep container .}
	\label{fig:FilialesEtClients}
\end{figure}
\paragraph{Dockernize Zeppelin}
Zeppelin is a notebook that allow as to interpret spark or cassandra . Zeppelin container is built on a 
an alpine linux operating system.
\label{sec:sec01}
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.2\textheight]{fig01/ZeppelinContainer}
	\mycaption[filiales et clients de Sofrecom.]{Zeppelin container.}
	\label{fig:FilialesEtClients}
\end{figure}
\subsection{Log Producer}
\label{sec:sec01}
The log producer is a Scala program that act as a producer for our kafka OSS. We ve used this log producer to perform
a real data stream flow.
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.3\textheight]{fig01/logProducer}
	\mycaption[filiales et clients de Sofrecom.]{Scala application log producer.}
	\label{fig:FilialesEtClients}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.6\textheight]{fig01/logProducer1}
	\mycaption[filiales et clients de Sofrecom.]{Scala application log producer.}
	\label{fig:FilialesEtClients}
\end{figure}

\subsection{Spark Jobs}
\label{sec:sec01}
Applying the lambda architecture require running at least two jobs, in our case we ve created three spark jobs using Scala :
\begin{itemize}
\item BatchSaveTOHDFS: This job persists realtime data to HDFS. It consumes data flow from Kafka and persist it to HDFS continuously.
\item StreamingProcessing: This job is the realtime engine, it consumes data from Kafka and process it and gives results in realtime. 
\item BatchProcessing: This job is the batch engine, it processes the data already persisted in HDFS and gives results each 8 hours.
\end{itemize}
\subsubsection{BatchProcessing}
\label{sec:sec01}
The next figure show the BatchProcessing job in it's accepted status:

\begin{figure}[h!]
	\centering
	\includegraphics[height=0.6\textheight]{fig01/SparkJobAccepted}
	\mycaption[filiales et clients de Sofrecom.]{BatchProcessing spark job in accepted status.}
	\label{fig:FilialesEtClients}
\end{figure}
\newpage
The next figure show the BatchProcessing job in it's running status:
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.5\textheight]{fig01/SparkJobRunning}
	\mycaption[filiales et clients de Sofrecom.]{BatchProcessing spark job in running status.}
	\label{fig:FilialesEtClients}
\end{figure}
\subsubsection{StreamingProcessing}
\label{sec:sec01}
\subsubsection{BatchSaveTOHDFS}
\label{sec:sec01}
\subsection{Show Resualts on Apache Zeppelin}
\label{sec:sec01}
The next figure show Analytics results displayed on Zeppelin dashboard :
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.3\textheight]{fig01/zeppelin}
	\mycaption[filiales et clients de Sofrecom.]{Zeppelin dashboard.}
	\label{fig:FilialesEtClients}
\end{figure}
\subsection{Account Managment}
\label{sec:sec01}
\subsubsection{Accounts}
\label{sec:sec01}
The next figure show the list Accounts :
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.3\textheight]{fig01/UserManagement}
	\mycaption[filiales et clients de Sofrecom.]{Account list.}
	\label{fig:FilialesEtClients}
\end{figure}
\subsubsection{Account add}
\label{sec:sec01}
The next figure show the form add account :
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.3\textheight]{fig01/UserManagementAdd}
	\mycaption[filiales et clients de Sofrecom.]{Add account.}
	\label{fig:FilialesEtClients}
\end{figure}
\subsubsection{Account Update}
\label{sec:sec01}
The next figure show the form update account :
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.3\textheight]{fig01/UserManagementUpdate}
	\mycaption[filiales et clients de Sofrecom.]{Update account.}
	\label{fig:FilialesEtClients}
\end{figure}
\subsection{Promotion Managment}
\label{sec:sec01}
\subsubsection{Promotions}
\label{sec:sec01}
The next figure show the list Promotions :
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.3\textheight]{fig01/PromotionManagement}
	\mycaption[filiales et clients de Sofrecom.]{Promotions list.}
	\label{fig:FilialesEtClients}
\end{figure}
\subsubsection{Promotion add}
\label{sec:sec01}
The next figure show the form add Promotion :
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.3\textheight]{fig01/PromotionAdd}
	\mycaption[filiales et clients de Sofrecom.]{Add promotions.}
	\label{fig:FilialesEtClients}
\end{figure}
\subsubsection{Promotion Update}
\label{sec:sec01}
The next figure show the form update Promotion :
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.3\textheight]{fig01/PromotionUpdate}
	\mycaption[filiales et clients de Sofrecom.]{Update promotions.}
	\label{fig:FilialesEtClients}
\end{figure}
\subsection{Display Analytics}
\label{sec:sec01}
The next figures show the Data Analytics Doshboard , this dashboard is update each time new data comes :
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.3\textheight]{fig01/Dashboard}
	\mycaption[filiales et clients de Sofrecom.]{Display analytics dashboard.}
	\label{fig:FilialesEtClients}
\end{figure}
\subsection{Heat Map users}
\label{sec:sec01}
The next figure show the Data Analytics Doshboard , this dashboard is update each time new data comes :
\begin{figure}[h!]
	\centering
	\includegraphics[height=0.3\textheight]{fig01/HeatMap}
	\mycaption[filiales et clients de Sofrecom.]{Heat map users dashboard.}
	\label{fig:FilialesEtClients}
\end{figure}
\subsection{Summary}
\label{sec:sec01}

\subsection{General conclusion}
\label{sec:sec01}


%=========================================================